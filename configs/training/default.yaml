# Default training configuration

# Training parameters
epochs: 100
save_every: 10
log_images_every: 5

# Optimizer settings
optimizer:
  name: adam
  lr: 0.001
  weight_decay: 0.0001
  betas: [0.9, 0.999]

# Learning rate scheduler
scheduler:
  name: cosine
  T_max: ${training.epochs}
  eta_min: 0.00001

# Loss function
loss:
  name: mse  # Options: mse, l1, bce, dice
